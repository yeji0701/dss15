{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import requests\n",
    "import json\n",
    "from scrapy.http import TextResponse\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'naver_article', using template directory 'C:\\Users\\luvu1\\anaconda3\\lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Code\\Programming\\PROGRAMMING\\05_SCRAPY\\naver_article\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd naver_article\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject naver_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=101\"\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36'}\n",
    "req = requests.get(url, headers=headers)\n",
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. xpath 찾기\n",
    "```[not()]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " ['https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=022&aid=0003522947',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=081&aid=0003139530',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=366&aid=0000619308',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0012012722',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=082&aid=0001042873',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=082&aid=0001042872',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=082&aid=0001042871',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0012012721',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=374&aid=0000225338',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=031&aid=0000568220',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=277&aid=0004791496',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=056&aid=0010933899',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=003&aid=0010184056',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0012012718',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=421&aid=0004988463',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=277&aid=0004791495',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=417&aid=0000618583',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=030&aid=0002912967',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=031&aid=0000568219',\n",
       "  'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=015&aid=0004449304'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = response.xpath('//*[@id=\"main_content\"]/div[2]/ul/li/dl/dt[not(@class=\"photo\")]/a/@href').extract()\n",
    "len(links), links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. items.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load naver_article/naver_article/items.py\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# https://docs.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class NaverArticleItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting naver_article/naver_article/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile naver_article/naver_article/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class NaverArticleItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    content = scrapy.Field()\n",
    "    category = scrapy.Field()\n",
    "    link = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting naver_article/naver_article/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile naver_article/naver_article/spiders/spider.py\n",
    "import scrapy\n",
    "from selenium import webdriver\n",
    "from naver_article.items import NaverArticleItem\n",
    "\n",
    "class ArticleSpider(scrapy.Spider):\n",
    "    name = \"NaverArticle\"\n",
    "    allow_domain = [\"https://news.naver.com\"]\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=101\"\n",
    "        \n",
    "        # selenium\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"headless\")\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "        elements = driver.find_elements_by_xpath('//*[@id=\"main_content\"]/div[2]/ul/li/dl/dt[not(@class=\"photo\")]/a')\n",
    "        links = [element.get_attribute(\"href\") for element in elements]\n",
    "        \n",
    "        for link in links:\n",
    "            yield scrapy.Request(link, callback=self.parse_content)\n",
    "            \n",
    "    def parse_content(self, response):\n",
    "        item = NaverArticleItem()\n",
    "        item[\"title\"] = response.xpath('//*[@id=\"articleTitle\"]/text()')[0].extract()\n",
    "        item[\"category\"] = response.url.split(\"sid1=\")[1].split(\"&\")[0]\n",
    "        content = response.xpath('//*[@id=\"articleBodyContents\"]/text()').extract()\n",
    "        item[\"content\"] = \" \".join(content).strip()\n",
    "        item[\"link\"] = response.url\n",
    "        yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. scrapy 프로젝트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd naver_article\n",
    "scrapy crawl NaverArticle -o article.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. pipelines 사용\n",
    "- 크롤링한 데이터를 mongodb에 저장\n",
    "- 크롤링한 데이터ㅓ에서 특정한 키워드가 있는 기사가 수집되면 slcak 메신저로 기사 내용과 링크 전송\n",
    "    - slack 메신저의 incoming webhook은 1초에 한번씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-3.11.0-cp38-cp38-win_amd64.whl (382 kB)\n",
      "Installing collected packages: pymongo\n",
      "Successfully installed pymongo-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['3.35.112.78:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient('mongodb://dss:dss@3.35.112.78:27017')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-9bccbec087a1>:3: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  collection.insert({\"title\":\"scrapy\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('5fae1b24bf9312832a900b38')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.naver_article\n",
    "collection = db.article\n",
    "collection.insert({\"title\":\"scrapy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing naver_article/naver_article/mongodb.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile naver_article/naver_article/mongodb.py\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://dss:dss@3.35.112.78:27017')\n",
    "db = client.naver_article\n",
    "collection = db.article\n",
    "collection.insert({\"title\":\"scrapy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load naver_article/naver_article/pipelines.py\n",
    "# Define your item pipelines here\n",
    "#\n",
    "# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n",
    "# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "\n",
    "\n",
    "# useful for handling different item types with a single interface\n",
    "from itemadapter import ItemAdapter\n",
    "\n",
    "\n",
    "class NaverArticlePipeline:\n",
    "    def process_item(self, item, spider):\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting naver_article/naver_article/pipelines.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile naver_article/naver_article/pipelines.py\n",
    "from itemadapter import ItemAdapter\n",
    "from .mongodb import collection\n",
    "\n",
    "class NaverArticlePipeline:\n",
    "    def process_item(self, item, spider):\n",
    "        data = {\n",
    "            \"title\": item[\"title\"],\n",
    "            \"category\": item[\"category\"],\n",
    "            \"content\": item[\"content\"],\n",
    "            \"link\": item[\"link\"],\n",
    "        }\n",
    "        collection.insert(data)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
